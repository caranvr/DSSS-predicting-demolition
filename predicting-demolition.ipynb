{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, MultiPoint\n",
    "from scipy.spatial import cKDTree\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting building demolition risk in Philadelphia's residential neighbourhoods, 2018-2021\n",
    "## Introduction and Literature Review\n",
    "\n",
    "### Predictors of demolition risk\n",
    "\n",
    "Proximity to the city centre or to public transport stops increases a property's risk of demolition (Weber et al., 2006). \n",
    "\n",
    "Both a neighbourhood's _status_ at the start of the period for analysis (in this case, 2018) and its prior _change_ are predictive of a property's demolition risk (Weber et al., 2006). \n",
    "\n",
    "## Presentation of Data\n",
    "### Data collection\n",
    "Data on demolitions, property-level, and neighbourhood-level characteristics was collected from various local and federal government sources. Given the large number of properties included in the dataset (over 500,000) and the number of features attached to each property (42), executing the code for data collection takes a considerable amount of time. This section therefore omits the full code, instead outlining the data collection process in detail. The code described in this section can be found in a separate notebook on [Github](https://github.com/caranvr/DSSS-predicting-demolition/blob/main/data-collection-code.ipynb).\n",
    "\n",
    "#### Demolitions\n",
    "\n",
    "The City of Philadelphia's Licenses and Inspections Department maintains a database of all demolition permits in the city issued since 2007. The addresses associated with private demolition permits from 2018-2021 were extracted, as public demolitions are more reflective of structural issues than consumer demand (Weber et al., 2006). \n",
    "\n",
    "#### Property characteristics\n",
    "\n",
    "The City of Philadelphia's Office of Property Assessments (OPA) maintains a regularly updated, georeferenced database of city properties, which contains building characteristics used to assess property tax rates. Due to the large size of the dataset, this database was accessed through an API call. Based on property characteristics found by Weber et al. (2006) to predict demolition risk, the following (non-identifying) features were selected:\n",
    "- **interior_condition**: a numeric code representing the quality of a property's interior. Properties are rated on a scale of 1 to 7, with 1 corresponding to new construction and 7 corresponding to \"structurally compromised\" (City of Philadelphia, 2021). A value of 0 indicates vacant land. \n",
    "- **exterior_condition**: a numeric code representing the property's external appearance, using the same scale as *interior_condition*. \n",
    "- **total_area**: the total area of the property.\n",
    "- **year_built**: the year the property was built.\n",
    "\n",
    "To match properties to Census tracts and find distances to relevant attractions, the latitude and longitude of each property were requested as well. In addition, **category_code_description** was selected, as Weber et al. (2006) only looked at single-family residential property demolition. Commercial, industrial, or multi-family residential properties may have different predictors of demolition risk. \n",
    "\n",
    "The most comprehensive property dataset is the most recent one. However, for 86.3% of properties with an associated demolition permit, the property assessment on file is from prior to demolition, or the building has not yet been demolished. The remaining properties have been re-assessed since their demolition and are now listed as vacant land. Since the model includes building characteristics, and these features are null for properties classed as 'Vacant Land', all properties in this category were dropped from the dataset. The remaining properties were matched against the demolition dataset to identify whether or not a demolition permit was attached to them after 2018. \n",
    "\n",
    "A separate OPA dataset was used to find each property's market value in 2018, then joined to the main properties dataset. \n",
    "\n",
    "#### Distance attributes\n",
    "\n",
    "In line with Ding and Hwang (2016), City Hall was used as a proxy for the city centre. The geopandas library was used to calculate the distance from each property to City Hall. \n",
    "\n",
    "Finding the distance from each property to its closest public transport stop was more involved, as there is no single shapefile of all public transport stops in the city. Therefore, shapefiles of commuter rail, subway, and trolley stops were downloaded and concatenated into one dataframe. This dataframe was then converted into a binary search tree using scipy's cKDTree method, which allowed for quick spatial querying.\n",
    "\n",
    "#### Neighbourhood attributes\n",
    "\n",
    "Due to data availability, neighbourhoods were defined as U.S. Census tracts, which have an average population of 4,000 residents (Weber et al., 2006; Oka and Wong, 2016). The U.S. Census American Community Survey (ACS) 2013-18 5-Year Estimates were used for 2018 demographic variables, while the Longitudinal Tract Database (LTDB) — which matches 2000 Census data to post-2010 Census tract boundaries (Logan et al., 2014) — was used for the same variables in 2000. \n",
    "\n",
    "For comparison to the LTDB variables, ACS columns related to higher education were summed. This was done during the data collection process to reduce the size of the full dataset. Properties were then spatially matched to Census tracts using the geopandas library. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in processed dataset in chunks to save memory\n",
    "chunks = []\n",
    "chunked_df = pd.read_csv('geo_props_final.csv', chunksize=40000)\n",
    "\n",
    "for chunk in chunked_df:\n",
    "    chunks.append(chunk)\n",
    "\n",
    "df = pd.concat(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lng</th>\n",
       "      <th>lat</th>\n",
       "      <th>location</th>\n",
       "      <th>category_code_description</th>\n",
       "      <th>interior_condition</th>\n",
       "      <th>exterior_condition</th>\n",
       "      <th>total_area</th>\n",
       "      <th>year_built</th>\n",
       "      <th>demolition</th>\n",
       "      <th>market_value</th>\n",
       "      <th>...</th>\n",
       "      <th>POP00</th>\n",
       "      <th>NHWHT00</th>\n",
       "      <th>NHBLK00</th>\n",
       "      <th>HISP00</th>\n",
       "      <th>HU00</th>\n",
       "      <th>OWN00</th>\n",
       "      <th>RENT00</th>\n",
       "      <th>AG25UP00</th>\n",
       "      <th>COL00</th>\n",
       "      <th>HINC00</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parcel_number</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11001660</th>\n",
       "      <td>-75.148540</td>\n",
       "      <td>39.931445</td>\n",
       "      <td>222 WHARTON ST</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1622.70</td>\n",
       "      <td>1960</td>\n",
       "      <td>0</td>\n",
       "      <td>212700.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3715.000108</td>\n",
       "      <td>1958.888794</td>\n",
       "      <td>809.169495</td>\n",
       "      <td>331.332611</td>\n",
       "      <td>1700.323242</td>\n",
       "      <td>808.19928</td>\n",
       "      <td>635.013733</td>\n",
       "      <td>2356.681885</td>\n",
       "      <td>317.74942</td>\n",
       "      <td>36532.250861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11001670</th>\n",
       "      <td>-75.148604</td>\n",
       "      <td>39.931452</td>\n",
       "      <td>224 WHARTON ST</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1624.50</td>\n",
       "      <td>1960</td>\n",
       "      <td>0</td>\n",
       "      <td>212800.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3715.000108</td>\n",
       "      <td>1958.888794</td>\n",
       "      <td>809.169495</td>\n",
       "      <td>331.332611</td>\n",
       "      <td>1700.323242</td>\n",
       "      <td>808.19928</td>\n",
       "      <td>635.013733</td>\n",
       "      <td>2356.681885</td>\n",
       "      <td>317.74942</td>\n",
       "      <td>36532.250861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11001680</th>\n",
       "      <td>-75.148668</td>\n",
       "      <td>39.931463</td>\n",
       "      <td>226 WHARTON ST</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1627.20</td>\n",
       "      <td>1960</td>\n",
       "      <td>0</td>\n",
       "      <td>212800.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3715.000108</td>\n",
       "      <td>1958.888794</td>\n",
       "      <td>809.169495</td>\n",
       "      <td>331.332611</td>\n",
       "      <td>1700.323242</td>\n",
       "      <td>808.19928</td>\n",
       "      <td>635.013733</td>\n",
       "      <td>2356.681885</td>\n",
       "      <td>317.74942</td>\n",
       "      <td>36532.250861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11001690</th>\n",
       "      <td>-75.148729</td>\n",
       "      <td>39.931470</td>\n",
       "      <td>228 WHARTON ST</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1683.90</td>\n",
       "      <td>1960</td>\n",
       "      <td>0</td>\n",
       "      <td>215000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3715.000108</td>\n",
       "      <td>1958.888794</td>\n",
       "      <td>809.169495</td>\n",
       "      <td>331.332611</td>\n",
       "      <td>1700.323242</td>\n",
       "      <td>808.19928</td>\n",
       "      <td>635.013733</td>\n",
       "      <td>2356.681885</td>\n",
       "      <td>317.74942</td>\n",
       "      <td>36532.250861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11003500</th>\n",
       "      <td>-75.147067</td>\n",
       "      <td>39.930988</td>\n",
       "      <td>108 SEARS ST</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>426.56</td>\n",
       "      <td>1920</td>\n",
       "      <td>0</td>\n",
       "      <td>140800.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3715.000108</td>\n",
       "      <td>1958.888794</td>\n",
       "      <td>809.169495</td>\n",
       "      <td>331.332611</td>\n",
       "      <td>1700.323242</td>\n",
       "      <td>808.19928</td>\n",
       "      <td>635.013733</td>\n",
       "      <td>2356.681885</td>\n",
       "      <td>317.74942</td>\n",
       "      <td>36532.250861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     lng        lat        location category_code_description  \\\n",
       "parcel_number                                                                   \n",
       "11001660      -75.148540  39.931445  222 WHARTON ST             Single Family   \n",
       "11001670      -75.148604  39.931452  224 WHARTON ST             Single Family   \n",
       "11001680      -75.148668  39.931463  226 WHARTON ST             Single Family   \n",
       "11001690      -75.148729  39.931470  228 WHARTON ST             Single Family   \n",
       "11003500      -75.147067  39.930988    108 SEARS ST             Single Family   \n",
       "\n",
       "               interior_condition  exterior_condition  total_area  year_built  \\\n",
       "parcel_number                                                                   \n",
       "11001660                      4.0                 4.0     1622.70        1960   \n",
       "11001670                      4.0                 4.0     1624.50        1960   \n",
       "11001680                      4.0                 4.0     1627.20        1960   \n",
       "11001690                      4.0                 4.0     1683.90        1960   \n",
       "11003500                      4.0                 4.0      426.56        1920   \n",
       "\n",
       "               demolition  market_value  ...        POP00      NHWHT00  \\\n",
       "parcel_number                            ...                             \n",
       "11001660                0      212700.0  ...  3715.000108  1958.888794   \n",
       "11001670                0      212800.0  ...  3715.000108  1958.888794   \n",
       "11001680                0      212800.0  ...  3715.000108  1958.888794   \n",
       "11001690                0      215000.0  ...  3715.000108  1958.888794   \n",
       "11003500                0      140800.0  ...  3715.000108  1958.888794   \n",
       "\n",
       "                  NHBLK00      HISP00         HU00      OWN00      RENT00  \\\n",
       "parcel_number                                                               \n",
       "11001660       809.169495  331.332611  1700.323242  808.19928  635.013733   \n",
       "11001670       809.169495  331.332611  1700.323242  808.19928  635.013733   \n",
       "11001680       809.169495  331.332611  1700.323242  808.19928  635.013733   \n",
       "11001690       809.169495  331.332611  1700.323242  808.19928  635.013733   \n",
       "11003500       809.169495  331.332611  1700.323242  808.19928  635.013733   \n",
       "\n",
       "                  AG25UP00      COL00        HINC00  \n",
       "parcel_number                                        \n",
       "11001660       2356.681885  317.74942  36532.250861  \n",
       "11001670       2356.681885  317.74942  36532.250861  \n",
       "11001680       2356.681885  317.74942  36532.250861  \n",
       "11001690       2356.681885  317.74942  36532.250861  \n",
       "11003500       2356.681885  317.74942  36532.250861  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.set_index('parcel_number', inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 534304 entries, 11001660 to 882150800\n",
      "Data columns (total 36 columns):\n",
      " #   Column                     Non-Null Count   Dtype  \n",
      "---  ------                     --------------   -----  \n",
      " 0   lng                        534304 non-null  float64\n",
      " 1   lat                        534304 non-null  float64\n",
      " 2   location                   534304 non-null  object \n",
      " 3   category_code_description  534304 non-null  object \n",
      " 4   interior_condition         533936 non-null  float64\n",
      " 5   exterior_condition         534253 non-null  float64\n",
      " 6   total_area                 534304 non-null  float64\n",
      " 7   year_built                 534304 non-null  int64  \n",
      " 8   demolition                 534304 non-null  int64  \n",
      " 9   market_value               532712 non-null  float64\n",
      " 10  geometry                   534304 non-null  object \n",
      " 11  dist_city_hall             534304 non-null  float64\n",
      " 12  dist_to_transport          534304 non-null  float64\n",
      " 13  index_right                534304 non-null  int64  \n",
      " 14  TRACTCE10                  534304 non-null  int64  \n",
      " 15  NAME10                     534304 non-null  float64\n",
      " 16  B01001_001E                534304 non-null  int64  \n",
      " 17  B03002_003E                534304 non-null  int64  \n",
      " 18  B03002_004E                534304 non-null  int64  \n",
      " 19  B03001_003E                534304 non-null  int64  \n",
      " 20  B25003_001E                534304 non-null  int64  \n",
      " 21  B25003_002E                534304 non-null  int64  \n",
      " 22  B25003_003E                534304 non-null  int64  \n",
      " 23  B15002_001E                534304 non-null  int64  \n",
      " 24  B19013_001E                534233 non-null  float64\n",
      " 25  COL18                      534304 non-null  int64  \n",
      " 26  POP00                      534304 non-null  float64\n",
      " 27  NHWHT00                    534304 non-null  float64\n",
      " 28  NHBLK00                    534304 non-null  float64\n",
      " 29  HISP00                     534304 non-null  float64\n",
      " 30  HU00                       534304 non-null  float64\n",
      " 31  OWN00                      534304 non-null  float64\n",
      " 32  RENT00                     534304 non-null  float64\n",
      " 33  AG25UP00                   534304 non-null  float64\n",
      " 34  COL00                      534304 non-null  float64\n",
      " 35  HINC00                     534304 non-null  float64\n",
      "dtypes: float64(20), int64(13), object(3)\n",
      "memory usage: 150.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns from the 2013-18 ACS were renamed for easier interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={\n",
    "    'B01001_001E': 'POP18',\n",
    "    'B03002_003E': 'NHWHT18',\n",
    "    'B03002_004E': 'NHBLK18',\n",
    "    'B03001_003E': 'HISP18',\n",
    "    'B25003_001E': 'HU18',\n",
    "    'B25003_002E': 'OWN18',\n",
    "    'B25003_003E': 'RENT18',\n",
    "    'B15002_001E': 'AG25UP18',\n",
    "    'B19013_001E': 'HINC18'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features that are on an ordinal scale were converted to category data types for later one-hot encoding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['category_code_description', 'interior_condition', 'exterior_condition']\n",
    "\n",
    "for c in cat_cols:\n",
    "    if c == 'category_code_description':\n",
    "        df[c] = df[c].astype('category')\n",
    "    else:\n",
    "        df[c] = df[c].astype(pd.UInt16Dtype()).astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns were then inspected for null values, which are not accepted in the classification methods used for this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>market_value</th>\n",
       "      <td>1592</td>\n",
       "      <td>0.297958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interior_condition</th>\n",
       "      <td>368</td>\n",
       "      <td>0.068875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HINC18</th>\n",
       "      <td>71</td>\n",
       "      <td>0.013288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exterior_condition</th>\n",
       "      <td>51</td>\n",
       "      <td>0.009545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HINC00</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Total   Percent\n",
       "market_value         1592  0.297958\n",
       "interior_condition    368  0.068875\n",
       "HINC18                 71  0.013288\n",
       "exterior_condition     51  0.009545\n",
       "HINC00                  0  0.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check for columns where most values are null\n",
    "total = df.isnull().sum().sort_values(ascending=False)\n",
    "percent = ((df.isnull().sum()/df.isnull().count())*100).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "missing_data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only four columns have missing data, and the percentage of rows in each column with missing values is small. Missing values can therefore be dropped or imputed without a significant impact on model bias.\n",
    "\n",
    "Given that interior_condition and exterior_condition are ordinal scales, the only option for imputing missing values in these columns is mode imputation. Mode imputation for these features may be inaccurate for individual properties, even if modal values from the same Census tract rather than the whole city were used, as buildings can vary significantly even within neighbourhoods. Thus, properties with missing values for these columns were dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07% of properties will be dropped\n"
     ]
    }
   ],
   "source": [
    "missing_bldgs = df.loc[\n",
    "    (df['interior_condition'].isnull()) |\n",
    "    (df['exterior_condition'].isnull())\n",
    "]\n",
    "\n",
    "print(f'{(missing_bldgs.shape[0]/df.shape[0])*100:.2f}% of properties will be dropped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(index=missing_bldgs.index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 2018 market value of an individual property _is_ related to the market value of neighbouring properties. Therefore, null values could be imputed with the median value of properties in the same Census tract. However, market value is also a function of property-level characteristics, which would not be taken into consideration during imputation. Properties with missing market values were thus dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29% of properties will be dropped\n"
     ]
    }
   ],
   "source": [
    "missing_values = df.loc[\n",
    "    df['market_value'].isnull()\n",
    "]\n",
    "\n",
    "print(f'{(missing_values.shape[0]/df.shape[0])*100:.2f}% of properties will be dropped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(index=missing_values.index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The properties missing a Census tract median income for 2018 were all in one of two Census tracts, meaning that two Census tracts were missing 2013-18 median income data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing values</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRACTCE10</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>989100</th>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980100</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Missing values\n",
       "TRACTCE10                \n",
       "989100                 39\n",
       "980100                 32"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(df.loc[\n",
    "    df['HINC18'].isnull()\n",
    "].groupby('TRACTCE10').size().sort_values(ascending=False)).rename(columns={0: 'Missing values'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that only 71 properties were affected and in two Census tracts, missing values were imputed with the median income in Philadelphia. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['HINC18'] = df['HINC18'].fillna(df['HINC18'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, the dataset was checked for invalid values in the 'year_built' column. Properties with a value of 0 in this column were dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33% of properties will be dropped\n"
     ]
    }
   ],
   "source": [
    "missing_years = df.loc[\n",
    "    df['year_built'] == 0\n",
    "]\n",
    "\n",
    "print(f'{(missing_years.shape[0]/df.shape[0])*100:.2f}% of properties will be dropped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(index=missing_years.index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(530680, 36)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature transformation\n",
    "\n",
    "For comparability between Census tracts, raw counts of residents or households in each demographic group were converted to percentages of a total, either of residents or housing units. (In line with U.S. Census practices, the number of residents with a Bachelor's degree or above was calculated as the proportion of residents _over 25_ with a Bachelor's degree or above.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert selected features to percentages\n",
    "def convert_to_pc(df, cols, denominator):\n",
    "    for c in cols:\n",
    "        df[c] = (df[c]/df[denominator])*100\n",
    "    return df\n",
    "\n",
    "pc_cols = {\n",
    "    'POP00': ['NHWHT00', 'NHBLK00', 'HISP00'], #key is denominator, value is list of columns to divide by denominator\n",
    "    'HU00': ['OWN00', 'RENT00'],\n",
    "    'AG25UP00': ['COL00'],\n",
    "    'POP18': ['NHWHT18', 'NHBLK18', 'HISP18'],\n",
    "    'HU18': ['OWN18', 'RENT18'],\n",
    "    'AG25UP18': ['COL18']\n",
    "}\n",
    "\n",
    "for k,v in pc_cols.items():\n",
    "    df = convert_to_pc(df,v,k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To measure change in neighbourhood characteristics, columns corresponding to 2000 were converted to the percentage point difference (for percentage columns) or percentage change (for total columns) in tract values from 2000 to 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert 2000 columns to percentage change from 2000-2018\n",
    "\n",
    "#Lookup for fields encoding percentage point difference from 2000 to 2018\n",
    "pc_diff = {\n",
    "    'NHWHT18': 'NHWHT00',\n",
    "    'NHBLK18': 'NHBLK00',\n",
    "    'HISP18': 'HISP00',\n",
    "    'OWN18': 'OWN00',\n",
    "    'RENT18': 'RENT00',\n",
    "    'COL18': 'COL00'\n",
    "}\n",
    "\n",
    "#Lookup for fields encoding percentage point change from 2000 to 2018 (counts)\n",
    "pc_change = {\n",
    "    'POP18': 'POP00', #total population\n",
    "    'HU18': 'HU00', #total housing units\n",
    "    'AG25UP18': 'AG25UP00', #25+ population\n",
    "    'HINC18': 'HINC00' #median household income\n",
    "}\n",
    "\n",
    "#Replace 2000 columns with the percentage change or difference from 2000 to 2018\n",
    "for k,v in pc_diff.items():\n",
    "    df[v] = df[k] - df[v]\n",
    "\n",
    "for k,v in pc_change.items():\n",
    "    df[v] = ((df[k] - df[v])/df[v])*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To enable classification, categorical features were converted into dummy variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cols = ['lng', 'lat', 'geometry', 'location', 'index_right', 'TRACTCE10', 'NAME10']\n",
    "X_cols = [c for c in df.columns.values if c not in id_cols and c != 'demolition']\n",
    "\n",
    "X = df[X_cols]\n",
    "Y = df[['demolition']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(530680, 46)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Histograms of continuous variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into training and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write function to tune hyperparameters for each classifier with GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tune hyperparameters using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-Nearest Neighbours classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tune hyperparameters using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results and Discussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Metrics for each classifier (table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix for each classifier (figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Map of false positives for each classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Map of false negatives for each classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
